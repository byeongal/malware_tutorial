{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "K = 1000\n",
    "\n",
    "def make_bin_image(md5):\n",
    "    with open('./kisa_2018/{}.vir'.format(md5), 'rb') as f:\n",
    "        file_data = f.read()\n",
    "    file_size = len(file_data)\n",
    "    if file_size < 10 * K:\n",
    "        image_width = 32\n",
    "    elif file_size < 30 * K:\n",
    "        image_width = 64\n",
    "    elif file_size < 60 * K:\n",
    "        image_width = 128\n",
    "    elif file_size < 100 * K:\n",
    "        image_width = 256\n",
    "    elif file_size < 200 * K:\n",
    "        image_width = 384\n",
    "    elif file_size < 500 * K:\n",
    "        image_width = 512\n",
    "    elif file_size < 1000 * K:\n",
    "        image_width = 768\n",
    "    else:\n",
    "        image_width = 1024\n",
    "    image_height = file_size // image_width\n",
    "    file_array = np.array(list(file_data[:image_width * image_height]))\n",
    "    file_img = np.reshape(file_array, (image_height, image_width))\n",
    "    file_img = np.uint8(file_img)\n",
    "    file_img = cv2.resize(file_img, (224, 224), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    cv2.imwrite('./m-cnn/{}.png'.format(md5), file_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train.csv', header = None)\n",
    "train_md5_list, train_labels = train_df[0], train_df[1]\n",
    "valid_df = pd.read_csv('valid.csv', header = None)\n",
    "valid_md5_list, valid_labels = valid_df[0], valid_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개수 : 20000\n",
      "악성 : 14000\n",
      "정상 : 6000\n"
     ]
    }
   ],
   "source": [
    "print('개수 :', len(train_md5_list))\n",
    "print('악성 :', sum(train_labels))\n",
    "print('정상 :', len(train_md5_list) - sum(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd62242fb2d040729027ee4256d33edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for md5 in tqdm(train_md5_list):\n",
    "    if os.path.exists('./m-cnn/{}.png'.format(md5)):\n",
    "        continue\n",
    "    make_bin_image(md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "def VGG16():\n",
    "    input_layer = Input((224, 224, 3, ))\n",
    "    block1_conv1 = Conv2D(filters=64, kernel_size=3, strides=1, padding = 'same', activation='relu')(input_layer)\n",
    "    block1_conv2 = Conv2D(filters=64, kernel_size=3, strides=1, padding = 'same', activation='relu')(block1_conv1)\n",
    "    block1_pooling = MaxPooling2D(pool_size=2, strides = 2)(block1_conv2)\n",
    "    \n",
    "    block2_conv1 = Conv2D(filters=128, kernel_size=3, strides=1, padding = 'same', activation='relu')(block1_pooling)\n",
    "    block2_conv2 = Conv2D(filters=128, kernel_size=3, strides=1, padding = 'same', activation='relu')(block2_conv1)\n",
    "    block2_pooling = MaxPooling2D(pool_size=2, strides = 2)(block2_conv2)\n",
    "    \n",
    "    block3_conv1 = Conv2D(filters=256, kernel_size=3, strides=1, padding = 'same', activation='relu')(block2_pooling)\n",
    "    block3_conv2 = Conv2D(filters=256, kernel_size=3, strides=1, padding = 'same', activation='relu')(block3_conv1)\n",
    "    block3_conv3 = Conv2D(filters=256, kernel_size=3, strides=1, padding = 'same', activation='relu')(block3_conv2)\n",
    "    block3_pooling = MaxPooling2D(pool_size=2, strides = 2)(block3_conv3)\n",
    "    \n",
    "    block4_conv1 = Conv2D(filters=512, kernel_size=3, strides=1, padding = 'same', activation='relu')(block3_pooling)\n",
    "    block4_conv2 = Conv2D(filters=512, kernel_size=3, strides=1, padding = 'same', activation='relu')(block4_conv1)\n",
    "    block4_conv3 = Conv2D(filters=512, kernel_size=3, strides=1, padding = 'same', activation='relu')(block4_conv2)\n",
    "    block4_pooling = MaxPooling2D(pool_size=2, strides = 2)(block4_conv3)\n",
    "    \n",
    "    block5_conv1 = Conv2D(filters=512, kernel_size=3, strides=1, padding = 'same', activation='relu')(block4_pooling)\n",
    "    block5_conv2 = Conv2D(filters=512, kernel_size=3, strides=1, padding = 'same', activation='relu')(block5_conv1)\n",
    "    block5_conv3 = Conv2D(filters=512, kernel_size=3, strides=1, padding = 'same', activation='relu')(block5_conv2)\n",
    "    block5_pooling = MaxPooling2D(pool_size=2, strides = 2)(block5_conv3)\n",
    "    \n",
    "    flatten = Flatten()(block5_pooling)\n",
    "    \n",
    "    fc1 = Dense(4096, activation='relu')(flatten)\n",
    "    fc2 = Dense(4096, activation='relu')(fc1)\n",
    "    output_layer = Dense(1, activation='sigmoid')(fc2)\n",
    "    \n",
    "    return Model(input_layer, output_layer)\n",
    "\n",
    "def VGG11():\n",
    "    input_layer = Input((224, 224, 3, ))\n",
    "    conv1 = Conv2D(filters=64, kernel_size=3, strides=1, padding = 'same', activation='relu')(input_layer)\n",
    "    pooling1 = MaxPooling2D(pool_size=2, strides = 2)(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(filters=128, kernel_size=3, strides=1, padding = 'same', activation='relu')(pooling1)\n",
    "    pooling2 = MaxPooling2D(pool_size=2, strides = 2)(conv2)\n",
    "    \n",
    "    conv3_1 = Conv2D(filters=256, kernel_size=3, strides=1, padding = 'same', activation='relu')(pooling2)\n",
    "    conv3_2 = Conv2D(filters=256, kernel_size=3, strides=1, padding = 'same', activation='relu')(conv3_1)\n",
    "    pooling3 = MaxPooling2D(pool_size=2, strides = 2)(conv3_2)\n",
    "    \n",
    "    conv4_1 = Conv2D(filters=512, kernel_size=3, strides=1, padding = 'same', activation='relu')(pooling3)\n",
    "    conv4_2 = Conv2D(filters=512, kernel_size=3, strides=1, padding = 'same', activation='relu')(conv4_1)\n",
    "    pooling4 = MaxPooling2D(pool_size=2, strides = 2)(conv4_2)\n",
    "    \n",
    "    conv5_1 = Conv2D(filters=512, kernel_size=3, strides=1, padding = 'same', activation='relu')(pooling4)\n",
    "    conv5_2 = Conv2D(filters=512, kernel_size=3, strides=1, padding = 'same', activation='relu')(conv5_1)\n",
    "    pooling5 = MaxPooling2D(pool_size=2, strides = 2)(conv5_2)\n",
    "    \n",
    "    flatten = Flatten()(pooling5)\n",
    "    \n",
    "    fc1 = Dense(4096, activation='relu')(flatten)\n",
    "    fc2 = Dense(4096, activation='relu')(fc1)\n",
    "    output_layer = Dense(1, activation='sigmoid')(fc2)\n",
    "    \n",
    "    return Model(input_layer, output_layer)\n",
    "    \n",
    "def VGGLite():\n",
    "    input_layer = Input((224, 224, 3, ))\n",
    "    block1_conv1 = Conv2D(filters=64, kernel_size=3, strides=1, padding = 'same', activation='relu')(input_layer)\n",
    "    block1_conv2 = Conv2D(filters=64, kernel_size=3, strides=1, padding = 'same', activation='relu')(block1_conv1)\n",
    "    block1_pooling = MaxPooling2D(pool_size=2, strides = 2)(block1_conv2)\n",
    "    \n",
    "    block2_conv1 = Conv2D(filters=128, kernel_size=3, strides=1, padding = 'same', activation='relu')(block1_pooling)\n",
    "    block2_conv2 = Conv2D(filters=128, kernel_size=3, strides=1, padding = 'same', activation='relu')(block2_conv1)\n",
    "    block2_pooling = MaxPooling2D(pool_size=2, strides = 2)(block2_conv2)\n",
    "    \n",
    "    gap = GlobalAveragePooling2D()(block2_pooling)\n",
    "    fc1 = Dense(128, activation='relu')(gap)\n",
    "    output_layer = Dense(1, activation='sigmoid')(fc1)\n",
    "    return Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGGLite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_120 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_10  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 276,801\n",
      "Trainable params: 276,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class DataSequence(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, shuffle=True):\n",
    "        self.x = x_set\n",
    "        self.y = np.array(y_set)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.x))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, md5_list):\n",
    "        vector_array = []\n",
    "        for md5 in md5_list:\n",
    "            img = cv2.imread('./m-cnn/{}.png'.format(md5)) / 255.0\n",
    "            vector_array.append(img)\n",
    "        return np.array(vector_array)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_x = self.x[indexes]\n",
    "        batch_y = self.y[indexes]\n",
    "        return self.__data_generation(batch_x), batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataSequence(train_md5_list, train_labels, 16)\n",
    "valid_generator = DataSequence(valid_md5_list, valid_labels, 16, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1250 [..............................] - ETA: 1:17 - loss: 0.6729 - acc: 0.5938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0210s vs `on_train_batch_end` time: 0.0557s). Check your callbacks.\n",
      "1250/1250 [==============================] - 83s 66ms/step - loss: 0.5855 - acc: 0.7139\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 83s 66ms/step - loss: 0.4889 - acc: 0.7771 \n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 81s 65ms/step - loss: 0.4207 - acc: 0.8116\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 82s 65ms/step - loss: 0.3714 - acc: 0.8364\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 82s 65ms/step - loss: 0.3388 - acc: 0.8525\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 82s 66ms/step - loss: 0.3047 - acc: 0.8688\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 83s 67ms/step - loss: 0.2733 - acc: 0.8853\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 83s 67ms/step - loss: 0.2494 - acc: 0.8964\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 83s 66ms/step - loss: 0.2293 - acc: 0.9074\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 83s 67ms/step - loss: 0.2135 - acc: 0.9125\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 73s 59ms/step - loss: 0.1961 - acc: 0.9212\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.1750 - acc: 0.9309\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.1621 - acc: 0.9380\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.1459 - acc: 0.9431\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.1326 - acc: 0.9475\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.1158 - acc: 0.9556\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.1045 - acc: 0.9593\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0954 - acc: 0.9639\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0866 - acc: 0.9670\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0730 - acc: 0.9719\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0713 - acc: 0.9740\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0620 - acc: 0.9779\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0613 - acc: 0.9769 0s - loss: 0.0607 \n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0487 - acc: 0.9816\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0490 - acc: 0.9822\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0416 - acc: 0.9847\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0432 - acc: 0.9843\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0412 - acc: 0.9855\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0357 - acc: 0.9864\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0370 - acc: 0.9858\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0294 - acc: 0.9886\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0323 - acc: 0.9883\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0350 - acc: 0.9875\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0301 - acc: 0.9894\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0202 - acc: 0.9933\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0274 - acc: 0.9898\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0293 - acc: 0.9884\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0231 - acc: 0.9918\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0200 - acc: 0.9926\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0283 - acc: 0.9901 0s - loss: 0.0284 - \n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0200 - acc: 0.9927\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0217 - acc: 0.9926\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0215 - acc: 0.9931\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0174 - acc: 0.9945\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0214 - acc: 0.9930\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0246 - acc: 0.9911\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0205 - acc: 0.9928\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0169 - acc: 0.9944\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0188 - acc: 0.9929\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0155 - acc: 0.9938\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0200 - acc: 0.9929\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0171 - acc: 0.9947\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0139 - acc: 0.9958\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0166 - acc: 0.9949\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0176 - acc: 0.9938\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0148 - acc: 0.9952\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0170 - acc: 0.9938\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0130 - acc: 0.9956\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0214 - acc: 0.9934\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0151 - acc: 0.9951\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0154 - acc: 0.9945\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0126 - acc: 0.9957\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0134 - acc: 0.9951\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0129 - acc: 0.9958\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0148 - acc: 0.9952\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0107 - acc: 0.9966\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0208 - acc: 0.9937\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0094 - acc: 0.9969\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0137 - acc: 0.9952\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0153 - acc: 0.9949\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0088 - acc: 0.9969 0s - loss: 0.0088 - acc:\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0118 - acc: 0.9963\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0128 - acc: 0.9960\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0151 - acc: 0.9949\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 1.1514e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 4.9514e-05 - acc: 1.0000\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 71s 57ms/step - loss: 1.2328e-05 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 7.1443e-06 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 5.3088e-06 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0394 - acc: 0.9896\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0122 - acc: 0.9959\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0107 - acc: 0.9966 0s - loss: 0.0107 - a\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0119 - acc: 0.9956\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0106 - acc: 0.9964\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0105 - acc: 0.9963\n",
      "Epoch 87/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0069 - acc: 0.9976\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0141 - acc: 0.9955\n",
      "Epoch 89/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0070 - acc: 0.9977\n",
      "Epoch 90/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0132 - acc: 0.9952\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0136 - acc: 0.9954\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0068 - acc: 0.9980\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0104 - acc: 0.9970\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0087 - acc: 0.9971\n",
      "Epoch 95/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0091 - acc: 0.9973\n",
      "Epoch 96/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0136 - acc: 0.9956\n",
      "Epoch 97/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0059 - acc: 0.9985\n",
      "Epoch 98/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0107 - acc: 0.9966\n",
      "Epoch 99/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0061 - acc: 0.9980\n",
      "Epoch 100/100\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.0129 - acc: 0.9958\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs = 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a894c132d66448b6a5e823dcefee315b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for md5 in tqdm(valid_md5_list):\n",
    "    if os.path.exists('./m-cnn/{}.png'.format(md5)):\n",
    "        continue\n",
    "    make_bin_image(md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 56s 45ms/step - loss: 0.7618 - acc: 0.8953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7617852091789246, 0.8953499794006348]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('m-cnn_lite.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
