{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train.csv', header = None)\n",
    "train_md5_list, train_labels = train_df[0], train_df[1]\n",
    "valid_df = pd.read_csv('valid.csv', header = None)\n",
    "valid_md5_list, valid_labels = valid_df[0], valid_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개수 : 20000\n",
      "악성 : 14000\n",
      "정상 : 6000\n"
     ]
    }
   ],
   "source": [
    "print('개수 :', len(train_md5_list))\n",
    "print('악성 :', sum(train_labels))\n",
    "print('정상 :', len(train_md5_list) - sum(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, Conv1D, multiply, GlobalMaxPool1D, Input, Activation, Lambda\n",
    "\n",
    "def Malconv(max_len=2000000, win_size=500, vocab_size=257):\n",
    "    inp = Input((max_len,))\n",
    "    emb = Embedding(vocab_size, 8)(inp)\n",
    "    conv_1 = Conv1D(kernel_size=(win_size), filters=128, strides=(win_size))(Lambda( lambda x : x[:,:,:4])(emb))\n",
    "    conv_2 = Conv1D(kernel_size=(win_size), filters=128, strides=(win_size), activation='sigmoid')(Lambda( lambda x : x[:,:,4:])(emb))\n",
    "    \n",
    "    mul = multiply([conv_1, conv_2])\n",
    "    pooling = Activation('relu')(GlobalMaxPool1D()(mul))\n",
    "    fc1 = Dense(128, activation='relu')(pooling)\n",
    "    fc2 = Dense(1, activation='sigmoid')(fc1)\n",
    "\n",
    "    return Model(inp, fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Malconv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2000000)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 2000000, 8)   2056        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 2000000, 4)   0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2000000, 4)   0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 4000, 128)    256128      lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 4000, 128)    256128      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 4000, 128)    0           conv1d[0][0]                     \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 128)          0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128)          0           global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          16512       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 530,953\n",
      "Trainable params: 530,953\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class DataSequence(Sequence):\n",
    "    def __init__(self, x_set, y_set , batch_size, shuffle=True):\n",
    "        self.x = x_set\n",
    "        self.y = np.array(y_set)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.x))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, fn_list):\n",
    "        data_files = []\n",
    "        for fn in fn_list:\n",
    "            with open(r\"./kisa_2018/{}.vir\".format(fn) , 'rb') as f:\n",
    "                tmp = [i+1 for i in f.read()[:2000000]]\n",
    "                tmp = tmp+[0]*(2000000-len(tmp))\n",
    "                data_files.append(tmp)\n",
    "        return np.array(data_files)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_x = self.__data_generation(self.x[indexes])\n",
    "        batch_y = self.y[indexes]\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataSequence(train_md5_list, train_labels, 16)\n",
    "valid_generator = DataSequence(valid_md5_list, valid_labels, 16, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1250/1250 [==============================] - 3428s 3s/step - loss: 0.3050 - acc: 0.8706\n",
      "Epoch 2/32\n",
      "1250/1250 [==============================] - 3413s 3s/step - loss: 0.1225 - acc: 0.9539\n",
      "Epoch 3/32\n",
      "1250/1250 [==============================] - 3413s 3s/step - loss: 0.0342 - acc: 0.9879\n",
      "Epoch 4/32\n",
      "1250/1250 [==============================] - 3415s 3s/step - loss: 0.0259 - acc: 0.9916\n",
      "Epoch 5/32\n",
      "1250/1250 [==============================] - 3414s 3s/step - loss: 0.0193 - acc: 0.9930\n",
      "Epoch 6/32\n",
      "1250/1250 [==============================] - 3418s 3s/step - loss: 0.0167 - acc: 0.9945\n",
      "Epoch 7/32\n",
      "1250/1250 [==============================] - 3420s 3s/step - loss: 0.0148 - acc: 0.9948\n",
      "Epoch 8/32\n",
      "1250/1250 [==============================] - 3420s 3s/step - loss: 0.0141 - acc: 0.9955\n",
      "Epoch 9/32\n",
      "1250/1250 [==============================] - 3419s 3s/step - loss: 0.0113 - acc: 0.9962\n",
      "Epoch 10/32\n",
      "1250/1250 [==============================] - 3420s 3s/step - loss: 0.0125 - acc: 0.9955\n",
      "Epoch 11/32\n",
      "1250/1250 [==============================] - 3423s 3s/step - loss: 0.0095 - acc: 0.9970\n",
      "Epoch 12/32\n",
      "1250/1250 [==============================] - 3423s 3s/step - loss: 0.0089 - acc: 0.9973\n",
      "Epoch 13/32\n",
      "1250/1250 [==============================] - 3422s 3s/step - loss: 0.0104 - acc: 0.9975\n",
      "Epoch 14/32\n",
      "1250/1250 [==============================] - 3421s 3s/step - loss: 0.0158 - acc: 0.9952\n",
      "Epoch 15/32\n",
      "1250/1250 [==============================] - 3421s 3s/step - loss: 0.0068 - acc: 0.9980\n",
      "Epoch 16/32\n",
      "1250/1250 [==============================] - 3421s 3s/step - loss: 0.0091 - acc: 0.9973\n",
      "Epoch 17/32\n",
      "1250/1250 [==============================] - 3421s 3s/step - loss: 0.0066 - acc: 0.9978\n",
      "Epoch 18/32\n",
      "1250/1250 [==============================] - 3420s 3s/step - loss: 0.0093 - acc: 0.9971\n",
      "Epoch 19/32\n",
      "1250/1250 [==============================] - 3423s 3s/step - loss: 0.0102 - acc: 0.9964\n",
      "Epoch 20/32\n",
      "1250/1250 [==============================] - 3430s 3s/step - loss: 0.0080 - acc: 0.9972\n",
      "Epoch 21/32\n",
      "1250/1250 [==============================] - 3417s 3s/step - loss: 0.0044 - acc: 0.9983\n",
      "Epoch 22/32\n",
      "1250/1250 [==============================] - 3425s 3s/step - loss: 0.0070 - acc: 0.9974\n",
      "Epoch 23/32\n",
      "1250/1250 [==============================] - 3429s 3s/step - loss: 0.0056 - acc: 0.9984\n",
      "Epoch 24/32\n",
      "1250/1250 [==============================] - 3433s 3s/step - loss: 0.0061 - acc: 0.9980\n",
      "Epoch 25/32\n",
      " 645/1250 [==============>...............] - ETA: 27:40 - loss: 0.0084 - acc: 0.9978"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_generator, epochs = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('malconv.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
